# -*- coding: utf-8 -*-
"""emotion-detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dYu-vf3e9PaToaQ-yVnNX6dWptiwh5Qs
"""

from keras.layers import Conv2D,MaxPool2D,BatchNormalization,Dropout,Flatten,Dense,Activation,LeakyReLU
from keras.models import Sequential
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix,classification_report
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping
import os
from keras.initializers import glorot_normal
from matplotlib.pyplot import imread,imshow
import matplotlib.pyplot as plt

main_path = '../input/work-with-data'

train_path = os.path.join(main_path,'train')
test_path = os.path.join(main_path,'test')

generator = ImageDataGenerator(rescale=1/255.0)

train_generator = generator.flow_from_directory(train_path,target_size=(48,48),class_mode='categorical',batch_size=128,color_mode='grayscale' )

train_generator.class_indices

validation_generator = generator.flow_from_directory(test_path,target_size=(48,48),class_mode='categorical',batch_size=128,color_mode='grayscale')

model = Sequential()

model.add(Conv2D(16,(5,5),strides=(1,1),kernel_initializer=glorot_normal(21),input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.3))
model.add(Conv2D(32,(3,3),strides=(1,1),kernel_initializer=glorot_normal(5)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPool2D((2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(64,(3,3),strides=(1,1),kernel_initializer=glorot_normal(3)))
model.add(BatchNormalization())
model.add(LeakyReLU(alpha=0.1))
model.add(Dropout(0.3))
model.add(Conv2D(128,(3,3),strides=(1,1),kernel_initializer=glorot_normal(10)))
model.add(BatchNormalization())
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPool2D((2,2)))
model.add(Dropout(0.5))

model.add(Conv2D(256,(2,2),strides=(1,1),kernel_initializer=glorot_normal(78)))
model.add(BatchNormalization())
model.add(LeakyReLU(alpha=0.1))
model.add(Dropout(0.4))
model.add(Conv2D(512,(2,2),strides=(1,1),kernel_initializer=glorot_normal(78)))
model.add(BatchNormalization())
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPool2D((2,2)))
model.add(Dropout(0.5))

model.add(Flatten())

model.add(Dense(1024,activation='relu'))
model.add(Dense(6,activation='softmax'))

print(model.summary())

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

early = EarlyStopping(patience=15)

steps_per_epoch = train_generator.n//128

model.fit(train_generator,steps_per_epoch = steps_per_epoch,epochs=100,callbacks=[early],validation_data=validation_generator)

loss = pd.DataFrame(model.history.history)

loss.head()

model.save('em_best.h5')

loss[['loss','val_loss']].plot()

loss[['accuracy','val_accuracy']].plot()

predict = model.predict_generator(validation_generator)

predict.shape

from keras.metrics import AUC

m = AUC(num_thresholds=50,curve='ROC')

predict = predict>0.5

validation_generator.classes

from sklearn.preprocessing import LabelBinarizer

binarise = LabelBinarizer()

m.update_state(y_enco_true,predict)

y_enco_true = binarise.fit_transform(validation_generator.classes)

y_enco_true.shape

np.array(m.result())

print(classification_report(y_enco_true,predict))

